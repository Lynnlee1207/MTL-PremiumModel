{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edff1d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm, trange\n",
    "import geopandas as gpd\n",
    "\n",
    "plt.style.use(\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e18d7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import X_freq, X_sev, df, sev_mask, w_freq, w_sev, y_freq, y_sev, all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088d9b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "nclaims_summary = df.groupby(\"nclaims\").agg(\"size\").to_frame(\"Count\")\n",
    "nclaims_summary[\"Freq\"] = (nclaims_summary[\"Count\"] / nclaims_summary[\"Count\"].sum()).map(\"{:.2%}\".format)\n",
    "nclaims_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3faa7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import FFNNPremiumModel, GAMPremiumModel, GBMPremiumModel, GLMPremiumModel, MTMoENNPremiumModel, MTNNPremiumModel\n",
    "\n",
    "models = {n: {fold: m.load(f\"{m.__name__}_fold_{fold}.pkl\") \n",
    "              for fold in range(1, 7)} for n, m in [\n",
    "    (\"GAM\", GAMPremiumModel), \n",
    "    (\"GLM\", GLMPremiumModel), \n",
    "    (\"GBM\", GBMPremiumModel), \n",
    "    (\"FFNN\", FFNNPremiumModel), \n",
    "    (\"MTNN\", MTNNPremiumModel), \n",
    "    (\"MTMoE\", MTMoENNPremiumModel)\n",
    "]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc41435",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"F\"] = df[\"nclaims\"] / df[\"expo\"]\n",
    "for agg_name, agg_col, agg_func in [\n",
    "    (\"Expected Frequency\", \"F\", \"mean\"), \n",
    "]:\n",
    "    for feature_type in [\"category\", \"int\"]:\n",
    "        cols = np.intersect1d(df.select_dtypes(include=[feature_type]).columns, all_features)\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=len(cols), figsize=(15, 3), constrained_layout=True)\n",
    "        for col, ax in zip(cols, axes):\n",
    "            x, counts = np.unique(df[col], return_counts=True)\n",
    "            y = df.groupby(col, observed=True).agg({agg_col: agg_func})[agg_col]\n",
    "            ax.bar(x, y, alpha=0.7)\n",
    "            ax.grid(axis='y', linestyle='--', alpha=0.4)\n",
    "            ax.set_xlabel(col)\n",
    "            ax.set_ylabel(agg_name)\n",
    "            ax.set_title(f\"{agg_name} per {col}\")\n",
    "        fig.savefig(f\"{agg_name.lower().replace(' ', '_')}_{feature_type}.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690c96e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodata = gpd.read_file(\"https://raw.githubusercontent.com/arneh61/Belgium-Map/master/Gemeenten.json\", columns=[\"geometry\", \"NAME_4\"]) \\\n",
    "    .set_crs(epsg=4326) \\\n",
    "    .rename(columns={\"NAME_4\": \"name\"}) \\\n",
    "    .merge(pd.read_csv(\"data/postcodes.csv\", index_col='name'), on='name') \\\n",
    "    .merge(df[['expo', 'nclaims', 'amount', 'ageph', 'power', 'agec', 'bm', 'postcode']].groupby('postcode').agg('mean').reset_index().set_index('postcode'),\n",
    "        on='postcode', how='left')\n",
    "\n",
    "cols = geodata.columns[3:]\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10), sharex=True, sharey=True, constrained_layout=True)\n",
    "\n",
    "for ax, col in zip(axes.flatten(), cols):\n",
    "    geodata.plot(ax=ax, column=col, legend=False, cmap=\"Blues\")\n",
    "    ax.set_title(f'Mean {col} per Region')\n",
    "    vmin = geodata[col].min()\n",
    "    vmax = geodata[col].max()\n",
    "    sm = plt.cm.ScalarMappable(cmap='Blues', norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "    cbar = plt.colorbar(sm, ax=ax)\n",
    "    ax.set_axis_off()\n",
    "\n",
    "fig.savefig(\"geodata_map.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d596f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygam.terms import TermList\n",
    "from pygam import GAM\n",
    "\n",
    "def plot_partial_dependence(gam: GAM, X: pd.DataFrame, save_prefix=None):\n",
    "    terms = gam.terms\n",
    "    assert isinstance(terms, TermList)\n",
    "\n",
    "    numerical_terms: list[int] = []\n",
    "    tensor_terms: list[int] = []\n",
    "    categorical_terms: list[int] = []\n",
    "    for term_idx, term in enumerate(terms):\n",
    "        if term.isintercept:\n",
    "            continue\n",
    "        match term.dtype:\n",
    "            case 'categorical':\n",
    "                categorical_terms.append(term_idx)\n",
    "            case 'numerical':\n",
    "                numerical_terms.append(term_idx)\n",
    "            case ['numerical', 'numerical']:\n",
    "                tensor_terms.append(term_idx)\n",
    "\n",
    "    print(\"Categorical Terms:\", categorical_terms)\n",
    "    print(\"Numerical Terms:\", numerical_terms)\n",
    "    print(\"Tensor Terms:\", tensor_terms)\n",
    "\n",
    "    fig_numerical, fig_categorical, fig_tensor = None, None, None\n",
    "\n",
    "    if len(numerical_terms) > 0:\n",
    "        fig_numerical, axis = plt.subplots(figsize=(10, 2), nrows=1, ncols=len(numerical_terms))\n",
    "        # plot numerical terms as 2D curve\n",
    "        for i, term_idx in enumerate(numerical_terms):\n",
    "            term = terms[term_idx]\n",
    "            feature_name = X.columns[term.feature]\n",
    "            feature_range = np.percentile(X[feature_name].dropna(), [2.5, 97.5])\n",
    "            # create a grid of values for the feature\n",
    "            XX = np.zeros((100, len(X.columns)))\n",
    "            XX[:, term.feature] = np.linspace(*feature_range, num=100) \n",
    "            XX_scaled = XX.copy()\n",
    "            pdep, confi = gam.partial_dependence(term=term_idx, width=0.95, X=XX_scaled)\n",
    "            ax = axis[i] if len(numerical_terms) > 1 else axis\n",
    "            ax.plot(XX[:, term.feature], pdep)\n",
    "            ax.plot(XX[:, term.feature], confi, c='#3276b5', ls='--')\n",
    "            ax.fill_between(XX[:, term.feature], confi[:, 0], confi[:, 1], color='#3276b5', alpha=0.2)\n",
    "            ax.set_title(feature_name)\n",
    "            ax.grid(linestyle='--', alpha=0.7, linewidth=0.5)\n",
    "\n",
    "        if save_prefix:\n",
    "            fig_numerical.savefig(f\"{save_prefix}_numerical_term_partial_dependence.pdf\", bbox_inches='tight')\n",
    "\n",
    "    # plot categorical terms as bar plots\n",
    "    if len(categorical_terms) > 0:\n",
    "\n",
    "        fig_categorical, axis = plt.subplots(figsize=(10, 2), nrows=1, ncols=len(categorical_terms))\n",
    "        for i, term_idx in enumerate(categorical_terms):\n",
    "\n",
    "            term = terms[term_idx]\n",
    "            feature_name = X.columns[term.feature]\n",
    "            categories = sorted(X[feature_name].unique())\n",
    "\n",
    "            XX = np.zeros((len(categories), len(X.columns)))\n",
    "            XX[:, term.feature] = np.arange(len(categories))\n",
    "            XX_scaled = XX.copy()\n",
    "            pdep, confi = gam.partial_dependence(term=term_idx, width=0.95, X=XX_scaled)\n",
    "            ax = axis[i] if len(categorical_terms) > 1 else axis\n",
    "            # add confidence intervals\n",
    "            ax.errorbar(XX[:, term.feature], pdep, yerr=np.abs(confi.T), fmt='o', color='#3276b5', capsize=5)\n",
    "            ax.scatter(XX[:, term.feature], pdep, s=100, alpha=0.7, zorder=100)\n",
    "            ax.set_title(feature_name)\n",
    "            ax.set_xticks(np.arange(len(categories)), labels=categories)\n",
    "            ax.set_xlim(-0.5, len(categories) - 0.5)\n",
    "            ax.grid(axis='y', linestyle='--', alpha=0.7, linewidth=0.5)\n",
    "\n",
    "        if save_prefix:\n",
    "            fig_categorical.savefig(f\"{save_prefix}_categorical_term_partial_dependence.pdf\", bbox_inches='tight')\n",
    "\n",
    "    # plot the tensor terms as 2D heatmaps\n",
    "    # fig_tensor, axis = plt.subplots(figsize=(10, 4), nrows=1, ncols=len(tensor_terms))\n",
    "    # create a subplots of two cols not equal ratio\n",
    "    if len(tensor_terms) > 0:\n",
    "        fig_tensor, axis = plt.subplots(figsize=(10, 4), nrows=1, ncols=len(tensor_terms), gridspec_kw={'width_ratios': [1, 2]})\n",
    "        for i, term_idx in enumerate(tensor_terms):\n",
    "            term = terms[term_idx]\n",
    "            feature_names = [X.columns[feat] for feat in term.feature]\n",
    "            feature_ranges = [(df[feat].min(), df[feat].max()) for feat in feature_names]\n",
    "\n",
    "            XX = np.zeros((100 * 100, len(X.columns)))\n",
    "            XX[:, term.feature] = np.array(np.meshgrid(*(np.linspace(*r, 100) for r in feature_ranges))).reshape(-1, 100*100).T\n",
    "            XX_scaled = XX.copy()\n",
    "            pdep, confi = gam.partial_dependence(term=term_idx, width=0.95, X=XX_scaled)\n",
    "            \n",
    "            ax = axis[i] if len(tensor_terms) > 1 else axis\n",
    "            assert isinstance(ax, plt.Axes) \n",
    "            ax.set_title(' Ã— '.join(feature_names))\n",
    "\n",
    "            levels = 50\n",
    "\n",
    "            if feature_names == ['long', 'lat']:\n",
    "                centroid = np.array([c.coords[0] for c in geodata['geometry'].centroid])\n",
    "                XX_centroid = np.zeros((len(centroid), len(X.columns)))\n",
    "                XX_centroid[:, term.feature] = centroid\n",
    "                XX_centroid_scaled = XX_centroid.copy()\n",
    "                pdep_centroid, confi = gam.partial_dependence(term=term_idx, width=0.95, X=XX_centroid_scaled)\n",
    "\n",
    "                vmin = (pdep_centroid.min() + pdep.min()) / 2\n",
    "                vmax = (pdep_centroid.max() + pdep.max()) / 2\n",
    "\n",
    "                geodata['color'] = pdep_centroid\n",
    "                ax.set_axis_off()\n",
    "\n",
    "            else:\n",
    "                vmin = pdep.min()\n",
    "                vmax = pdep.max() \n",
    "\n",
    "            contour = ax.contourf(XX[:, term.feature[0]].reshape(100, 100),\n",
    "                                XX[:, term.feature[1]].reshape(100, 100),\n",
    "                                pdep.reshape(100, 100), levels=levels, cmap='Blues', alpha=0.8,\n",
    "                                vmin=vmin, vmax=vmax)\n",
    "            \n",
    "            if feature_names == ['long', 'lat']:\n",
    "                geodata.plot(ax=ax, column='color', cmap='Blues', edgecolor='white', linewidth=0.5, alpha=0.8, vmin=vmin, vmax=vmax)\n",
    "\n",
    "            plt.colorbar(contour, ax=ax, orientation='vertical')\n",
    "\n",
    "            ax.set_xlim(feature_ranges[0])\n",
    "            ax.set_ylim(feature_ranges[1])\n",
    "            ax.set_xlabel(feature_names[0])\n",
    "            ax.set_ylabel(feature_names[1])\n",
    "            ax.grid(linestyle='--', alpha=0.7, linewidth=0.5)\n",
    "\n",
    "        if save_prefix:\n",
    "            fig_tensor.savefig(f\"{save_prefix}_tensor_term_partial_dependence.pdf\", bbox_inches='tight')\n",
    "\n",
    "    return fig_numerical, fig_categorical, fig_tensor\n",
    "\n",
    "plot_partial_dependence(models[\"GAM\"][1].frequency_model, X_freq, save_prefix=\"frequency\")\n",
    "plot_partial_dependence(models[\"GAM\"][1].severity_model, X_sev, save_prefix=\"severity\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697b307a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = {\n",
    "    \"GAM\": pd.read_pickle(\"gam_results.pkl\"),\n",
    "    \"GLM (binned)\": pd.read_csv(\"glm_results.csv\"),\n",
    "    \"GLM (original)\": pd.read_csv(\"glm_original_results.csv\"),\n",
    "    \"GBM (binned)\": pd.read_csv(\"gbm_results.csv\"),\n",
    "    \"GBM (original)\": pd.read_csv(\"gbm_original_results.csv\"),\n",
    "    \"FFNN (binned)\": pd.read_csv(\"ffnn_pytorch_results.csv\"),\n",
    "    \"FFNN (original)\": pd.read_csv(\"ffnn_original_results.csv\"),\n",
    "    \"MTNN (binned)\": pd.read_csv(\"multitask_results_final2.csv\"),\n",
    "    \"MTNN (original)\": pd.read_csv(\"mtl_original_results_final2.csv\"),\n",
    "    \"MTMoE (binned)\": pd.read_csv(\"moe_multitask_results_test2.csv\"),\n",
    "    \"MTMoE (original)\": pd.read_csv(\"moe_original_results_test2.csv\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c6183d",
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_loss = df.groupby('fold').agg({\"amount\": \"sum\"})['amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8b0c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_results_df = pd.DataFrame(index=list(model_results.keys()), columns=[\"predicted_loss\", \"freq_deviance\", \"sev_deviance\", \"price_ratios\"])\n",
    "freq_deviance_df = pd.DataFrame(index=list(model_results.keys()), columns=[f\"Fold {i}\" for i in range(1, 7)])\n",
    "sev_deviance_df = pd.DataFrame(index=list(model_results.keys()), columns=[f\"Fold {i}\" for i in range(1, 7)])\n",
    "price_ratios_df = pd.DataFrame(index=list(model_results.keys()), columns=[f\"Fold {i}\" for i in range(1, 7)])\n",
    "\n",
    "model_names = []\n",
    "for model_name, model_df in model_results.items():\n",
    "    model_names.append(model_name)\n",
    "    model_df = model_df.set_index(\"fold\")\n",
    "    model_df[\"predicted_loss\"] = observed_loss * model_df[\"price_ratios\"]\n",
    "    average_results_df.loc[model_name] =  model_df.agg({\n",
    "        \"predicted_loss\": \"sum\",\n",
    "        \"freq_deviance\": \"mean\",\n",
    "        \"sev_deviance\": \"mean\",\n",
    "        \"price_ratios\": \"mean\",\n",
    "    })\n",
    "    freq_deviance_df.loc[model_name, :] = model_df[\"freq_deviance\"].values\n",
    "    sev_deviance_df.loc[model_name, :] = model_df[\"sev_deviance\"].values\n",
    "    price_ratios_df.loc[model_name, :] = model_df[\"price_ratios\"].values\n",
    "\n",
    "freq_deviance_df[\"Mean\"] = freq_deviance_df.mean(axis=1)\n",
    "sev_deviance_df[\"Mean\"] = sev_deviance_df.mean(axis=1)\n",
    "price_ratios_df[\"Mean\"] = price_ratios_df.mean(axis=1)\n",
    "average_results_df['predicted_loss'] = average_results_df['predicted_loss'].astype(int)\n",
    "display(average_results_df)\n",
    "display(freq_deviance_df)\n",
    "display(sev_deviance_df)\n",
    "display(price_ratios_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70661bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(16, 5))\n",
    "plt.subplots_adjust(wspace=0.1)  # Add right margin\n",
    "\n",
    "for i, (ax, key, title) in enumerate(zip(axes, [\"price_ratios\", \"freq_deviance\", \"sev_deviance\"], [\"Price Ratios Comparison\", \"Frequency Deviance Comparison\", \"Severity Deviance Comparison\"])):\n",
    "    compare_df = pd.DataFrame({\n",
    "        \"GAM\": gam_results_df[key],\n",
    "        \"GLM (binned)\": glm_binned_results_df[key],\n",
    "        \"GLM (original)\": glm_original_results_df[key],\n",
    "        \"GBM (binned)\": gbm_binned_results_df[key],\n",
    "        \"GBM (original)\": gbm_original_results_df[key],\n",
    "        \"FFNN (binned)\": ffnn_binned_results_df[key],\n",
    "        \"FFNN (original)\": ffnn_original_results_df[key],\n",
    "        \"MTL (binned)\": mtnn_binned_results_df[key],\n",
    "        \"MTL (original)\": mtnn_original_results_df[key],\n",
    "        \"MTL-MOE (binned)\": mtmoe_binned_results_df[key],\n",
    "        \"MTL-MOE (original)\": mtmoe_original_results_df[key],\n",
    "    })\n",
    "\n",
    "    melted_df = compare_df.melt(var_name=\"Model\", value_name=key)\n",
    "    sns.boxplot(data=compare_df, orient=\"h\", palette=\"Set2\", ax=ax)\n",
    "    sns.stripplot(data=melted_df, x=key, y=\"Model\", hue=\"Model\", palette=\"Set2\", size=8, alpha=1, linewidth=0.5, jitter=False, ax=ax)\n",
    "\n",
    "    n_folds, n_methods = compare_df.shape\n",
    "    for fold in range(n_folds):\n",
    "        ax.plot(compare_df.iloc[fold, :], np.arange(n_methods), marker=\"o\", linestyle=\"--\", alpha=0.2, linewidth=1, color=\"black\", markersize=4)\n",
    "\n",
    "    ax.set_title(title, fontsize=14)\n",
    "    ax.set_xlabel(\"\")\n",
    "    if i > 0:\n",
    "        ax.set_ylabel(\"\")\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    ax.tick_params(axis=\"y\", labelsize=9)\n",
    "    ax.grid(axis=\"x\", alpha=0.3)\n",
    "\n",
    "axes[0].axvline(x=1.0, color=\"black\", linestyle=\"--\", alpha=0.8, linewidth=2, label=\"Perfect Price Ratio (1.0)\", zorder=-10)\n",
    "fig.savefig(\"price_ratio_and_deviance_comparison.pdf\", bbox_inches=\"tight\", dpi=300, pad_inches=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cee1608",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_expected_vs_predicted(y_pred, y_true, bins=100, delta=None, ax=None, y_min=None, y_max=None, line_kwargs={}):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    if y_min is None:\n",
    "        y_min = y_pred.min()\n",
    "    if y_max is None:\n",
    "        y_max = y_pred.max()\n",
    "    if delta is None:\n",
    "        delta = (y_max - y_min) / 10\n",
    "\n",
    "    bins = 100\n",
    "    S = np.linspace(y_min, y_max, bins)\n",
    "    E = np.array([y_true[(y_pred >= s - delta) & (y_pred <= s + delta)].mean() for s in S])\n",
    "\n",
    "    ax.plot(S, E, **line_kwargs)\n",
    "    ax.plot([y_min, y_max], [y_min, y_max], color=\"black\", linestyle=\"--\", linewidth=2)\n",
    "\n",
    "\n",
    "def plot_histogram(y_pred, bins=100, ax=None, y_min=None, y_max=None, hist_kwargs={}, kde_kwargs={}):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    if y_min is None:\n",
    "        y_min = y_pred.min()\n",
    "    if y_max is None:\n",
    "        y_max = y_pred.max()\n",
    "\n",
    "    ax.hist(y_pred, bins=bins, range=(y_min, y_max), **hist_kwargs, density=True)\n",
    "    ax.set_xlim(y_min, y_max)\n",
    "    sns.kdeplot(y_pred, ax=ax, **kde_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33cab08",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = sns.color_palette(\"Dark2\", n_colors=len(models))\n",
    "cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cd72db",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = {}\n",
    "for fold in range(1, 7):\n",
    "    test_mask = df[\"fold\"] == fold\n",
    "\n",
    "    for i, (name, m) in enumerate(models.items()):\n",
    "        freq_pred, sev_pred = m[fold].predict(X_freq[test_mask], X_sev[test_mask])\n",
    "        price_ratio = float((freq_pred * sev_pred * df[\"expo\"][test_mask]).sum() / df[\"amount\"][test_mask].sum())\n",
    "        sev_pred = sev_pred[sev_mask[test_mask]]\n",
    "        freq_true = df[\"nclaims\"][test_mask].to_numpy() / df[\"expo\"][test_mask].to_numpy()\n",
    "        sev_true = df[\"average\"][test_mask & sev_mask].to_numpy()\n",
    "        test_predictions[(fold, name)] = (freq_pred, sev_pred, freq_true, sev_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c42faab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, axes1 = plt.subplots(figsize=(15, 5), ncols=6, nrows=2)\n",
    "fig2, axes2 = plt.subplots(figsize=(15, 5), ncols=6, nrows=2)\n",
    "\n",
    "fig1.subplots_adjust(hspace=0.2)\n",
    "fig2.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "\n",
    "\n",
    "for i, (name, m) in enumerate(models.items()):\n",
    "    freq_preds = []\n",
    "    sev_preds = []\n",
    "    for fold in range(1, 7):\n",
    "        freq_pred, sev_pred, freq_true, sev_true = test_predictions[(fold, name)]\n",
    "        plot_expected_vs_predicted(freq_pred, freq_true, bins=100, ax=axes1[0, i], y_min=0.05, y_max=0.2, line_kwargs=dict(color=cmap[i], linewidth=2, alpha=0.5))\n",
    "        plot_expected_vs_predicted(sev_pred, sev_true, bins=100, ax=axes1[1, i], y_min=1000, y_max=1400, delta=100, line_kwargs=dict(color=cmap[i], linewidth=2, alpha=0.5))\n",
    "        freq_preds.append(freq_pred)\n",
    "        sev_preds.append(sev_pred)\n",
    "\n",
    "    plot_histogram(np.hstack(freq_preds), bins=100, ax=axes2[0, i], hist_kwargs=dict(color=cmap[i], alpha=0.5), kde_kwargs=dict(color=cmap[i], alpha=0.8))\n",
    "    plot_histogram(np.hstack(sev_preds), bins=100, ax=axes2[1, i], hist_kwargs=dict(color=cmap[i], alpha=0.5), kde_kwargs=dict(color=cmap[i], alpha=0.8))\n",
    "\n",
    "\n",
    "freq_range = [0.05, 0.2]\n",
    "sev_range = [1000, 1400]\n",
    "freq_ticks = np.arange(0.05, 0.21, 0.05)\n",
    "sev_ticks = np.arange(1050, 1500, 150)\n",
    "freq_density_max = 18\n",
    "sev_density_max = 0.007\n",
    "\n",
    "for i, name in enumerate(models):\n",
    "    axes1[0, i].set_xlim(freq_range)\n",
    "    axes1[0, i].set_ylim(freq_range)\n",
    "    axes1[0, i].set_xticks(freq_ticks)\n",
    "    axes1[0, i].set_title(name, fontsize=12)\n",
    "    axes1[0, i].grid(axis=\"both\", alpha=0.3)\n",
    "\n",
    "    axes1[1, i].set_xticks(sev_ticks)\n",
    "    axes1[1, i].set_yticks(sev_ticks)\n",
    "    axes1[1, i].set_xlim(sev_range)\n",
    "    axes1[1, i].set_ylim(sev_range)\n",
    "    axes1[1, i].grid(axis=\"both\", alpha=0.3)\n",
    "\n",
    "    axes2[0, i].set_title(name, fontsize=12)\n",
    "    axes2[0, i].set_xlabel(\"Frequency\", fontsize=10)\n",
    "    axes2[1, i].set_xlabel(\"Severity\", fontsize=10)\n",
    "    axes2[0, i].set_xlim(freq_range)\n",
    "    axes2[0, i].set_xticks(freq_ticks)\n",
    "    axes2[1, i].set_xlim(sev_range)\n",
    "    axes2[1, i].set_xticks(sev_ticks)\n",
    "    axes2[0, i].set_ylim(0, freq_density_max)\n",
    "    axes2[1, i].set_ylim(0, sev_density_max)\n",
    "\n",
    "    if i > 0:\n",
    "        axes1[0, i].set_yticklabels([])\n",
    "        axes1[1, i].set_yticklabels([])\n",
    "        axes1[0, i].set_ylabel(\"\")\n",
    "        axes1[1, i].set_ylabel(\"\")\n",
    "        axes2[0, i].set_ylabel(\"\")\n",
    "        axes2[1, i].set_ylabel(\"\")\n",
    "\n",
    "axes1[0, 0].set_ylabel(\"Frequency\")\n",
    "axes1[1, 0].set_ylabel(\"Severity\")\n",
    "axes2[0, 0].set_ylabel(\"Density\")\n",
    "axes2[1, 0].set_ylabel(\"Density\")\n",
    "\n",
    "fig1.text(x=0.06, y=0.35, s=\"Average Observation\", fontsize=12, rotation=90)\n",
    "fig1.text(x=0.45, y=0, s=\"Predicted Expectation\", fontsize=12, rotation=0)\n",
    "fig1.savefig(\"expected_vs_predicted_freq_sev.pdf\", bbox_inches=\"tight\")\n",
    "fig2.savefig(\"histogram_freq_sev.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1f1893",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{E}[Y \\mid f(X) \\in [s- \\delta , s + \\delta]]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\{(s, ~ \\mathbb{E}[y_\\text{true} \\mid y_\\text{pred} \\in [s - \\delta , s + \\delta]) ~ |~ s \\in S \\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc54c668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_col(df, col, value):\n",
    "    if col in df.columns:\n",
    "        new_df = df.copy()\n",
    "        new_df.loc[:, col] = value\n",
    "        return new_df\n",
    "    return df\n",
    "\n",
    "\n",
    "def random_col(df, col):\n",
    "    if col in df.columns:\n",
    "        return set_col(df, col, np.random.permutation(df[col].values))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda00a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"coverage\", \"fuel\", \"ageph\", \"power\", \"bm\", \"long\", \"lat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e231b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "freq_VIP_df = pd.DataFrame(index=features, columns=list(models.keys()))\n",
    "sev_VIP_df = pd.DataFrame(index=features, columns=list(models.keys()))\n",
    "freq_VIP_df.loc[:, :] = 0\n",
    "sev_VIP_df.loc[:, :] = 0\n",
    "\n",
    "for fold in trange(1, 7):\n",
    "    for name, m in models.items():\n",
    "        for feat in features:\n",
    "            X_freq_rand = random_col(X_freq, feat)\n",
    "            X_sev_rand = random_col(X_sev, feat)\n",
    "            freq_pred, sev_pred = m[fold].predict(X_freq, X_sev)\n",
    "            freq_pred_rand, sev_pred_rand = m[fold].predict(X_freq_rand, X_sev_rand)\n",
    "            freq_VIP_df.loc[feat, name] += np.sum(np.abs(freq_pred_rand - freq_pred))\n",
    "            sev_VIP_df.loc[feat, name] += np.sum(np.abs(sev_pred_rand - sev_pred))\n",
    "\n",
    "freq_VIP_df /= freq_VIP_df.sum(axis=0)\n",
    "sev_VIP_df /= sev_VIP_df.sum(axis=0)\n",
    "\n",
    "freq_VIP_df.to_csv(\"freq_VIP.csv\")\n",
    "sev_VIP_df.to_csv(\"sev_VIP.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82488963",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_VIP_df = pd.read_csv(\"freq_VIP.csv\", index_col=0)\n",
    "sev_VIP_df = pd.read_csv(\"sev_VIP.csv\", index_col=0)\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(10, 6), nrows=1, ncols=2)\n",
    "fig.subplots_adjust(wspace=0.1)\n",
    "\n",
    "def plot_vip(df, ax, title):\n",
    "    df = df.reset_index().melt(id_vars='index', var_name='Model', value_name='VIP')\n",
    "    sns.barplot(data=df, y='index', x='VIP', hue='Model', palette='Dark2', alpha=0.6, ax=ax, orient='h')\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(\"Features\")\n",
    "    ax.set_xlabel(\"VIP\")\n",
    "    ax.set_yticks(range(len(features)), features)\n",
    "    ax.get_legend().remove()  # Remove individual legends\n",
    "\n",
    "plot_vip(freq_VIP_df, axes[0], \"Frequency Variable Importance Plot (VIP)\")\n",
    "plot_vip(sev_VIP_df, axes[1], \"Severity Variable Importance Plot (VIP)\")\n",
    "\n",
    "axes[1].set_yticklabels([])\n",
    "axes[1].set_ylabel(\"\")\n",
    "\n",
    "axes[0].grid(axis='both', alpha=0.4)\n",
    "axes[1].grid(axis='both', alpha=0.4)\n",
    "\n",
    "# Create a common legend\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='lower center', bbox_to_anchor=(0.5, -0.05), ncol=len(labels))\n",
    "fig.savefig(\"vip_scores.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82cb199",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_significant_features = freq_VIP_df.sum(axis=1).sort_values(ascending=False)[:2].index.tolist()\n",
    "sev_significant_features = sev_VIP_df.sum(axis=1).sort_values(ascending=False)[:2].index.tolist()\n",
    "print(\"Most significant frequency features:\", freq_significant_features)\n",
    "print(\"Most significant severity features:\", sev_significant_features)\n",
    "\n",
    "# significant_features = [\"bm\", \"ageph\"]  # Use the most significant features for PD calculation\n",
    "significant_features = [\"bm\", \"ageph\"]  # Use the most significant features for PD calculation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012a3e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_PD: dict[str, dict[str, dict[float, float]]] = {}\n",
    "sev_PD: dict[str, dict[str, dict[float, float]]] = {}\n",
    "\n",
    "pbar = tqdm(total=len(models) * len(significant_features), desc=\"Calculating PD scores\", unit=\"feat\")\n",
    "\n",
    "for feat in significant_features:\n",
    "    freq_PD[feat] = {}\n",
    "    sev_PD[feat] = {}\n",
    "\n",
    "    # if categorical\n",
    "    if X_freq[feat].dtype == \"categorical\":\n",
    "        possible_values = X_freq[feat].cat.categories\n",
    "    # if integer \n",
    "    elif X_freq[feat].dtype in (\"int64\", \"int32\"):\n",
    "        possible_values = np.unique(X_freq[feat])\n",
    "    elif X_freq[feat].dtype == \"float64\":\n",
    "        possible_values = np.linspace(X_freq[feat].min(), X_freq[feat].max(), 10)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported feature type for {feat}: {X_freq[feat].dtype}\")\n",
    "    \n",
    "    for name, m in models.items():\n",
    "        freq_PD[feat][name] = {}\n",
    "        sev_PD[feat][name] = {}\n",
    "\n",
    "        pbar.set_description(f\"Calculating PD scores for {name}\", refresh=True)\n",
    "\n",
    "        for value in possible_values:\n",
    "            freq_PD[feat][name][value] = 0.0\n",
    "            sev_PD[feat][name][value] = 0.0\n",
    "            \n",
    "            for fold in range(1, 7):\n",
    "                X_freq_rand = set_col(X_freq, feat, value)\n",
    "                X_sev_rand = set_col(X_sev, feat, value)\n",
    "                freq_pred, sev_pred = m[fold].predict(X_freq_rand, X_sev_rand)\n",
    "                freq_PD[feat][name][value] += freq_pred.mean()\n",
    "                sev_PD[feat][name][value] += sev_pred.mean()\n",
    "            freq_PD[feat][name][value] /= 6\n",
    "            sev_PD[feat][name][value] /= 6\n",
    "\n",
    "        pbar.update(1)\n",
    "\n",
    "\n",
    "pickle.dump(freq_PD, open(\"freq_PD.pkl\", \"wb\"))\n",
    "pickle.dump(sev_PD, open(\"sev_PD.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dba38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_PD = pickle.load(open(\"freq_PD.pkl\", \"rb\"))\n",
    "sev_PD = pickle.load(open(\"sev_PD.pkl\", \"rb\"))\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(10, 6), nrows=2, ncols=len(significant_features))\n",
    "fig.subplots_adjust(wspace=0.2, hspace=0.1)\n",
    "for i, feat in enumerate(significant_features):\n",
    "    is_categorical = X_freq[feat].dtype == \"category\"\n",
    "    for j, name in enumerate(models):\n",
    "        if is_categorical:\n",
    "            raise NotImplementedError(\"Categorical features not supported in this plot.\")\n",
    "        else:\n",
    "            axes[0, i].plot(freq_PD[feat][name].keys(), freq_PD[feat][name].values(), label=name, color=cmap[j])\n",
    "            axes[1, i].plot(sev_PD[feat][name].keys(), sev_PD[feat][name].values(), label=name, color=cmap[j])\n",
    "    \n",
    "    axes[0, i].grid(axis='both', alpha=0.4)\n",
    "    axes[1, i].grid(axis='both', alpha=0.4)\n",
    "    axes[0, i].set_xlim(X_freq[feat].min(), X_freq[feat].max())\n",
    "    axes[1, i].set_xlim(X_freq[feat].min(), X_freq[feat].max())\n",
    "    axes[-1, i].set_xlabel(feat)\n",
    "    \n",
    "axes[0, 0].set_xticklabels([])\n",
    "axes[0, 1].set_xticklabels([])\n",
    "\n",
    "axes[0, 0].set_ylabel(\"Frequency\")\n",
    "axes[1, 0].set_ylabel(\"Severity\")\n",
    "\n",
    "\n",
    "# Create a common legend\n",
    "handles, labels = axes[0, 0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='lower center', bbox_to_anchor=(0.5, -0.05), ncol=len(labels))\n",
    "fig.savefig(\"partial_dependence_plots.pdf\", bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
